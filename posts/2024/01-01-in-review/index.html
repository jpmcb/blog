<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>2023 in review | John McBride</title>
<meta name=keywords content><meta name=description content="I had a huge year.
And every year, around this time, when I have a well deserved opportunity to
take a break and prepare for the next year, I like to reflect:
think on the year&rsquo;s accomplishments, derive some lessons learned, and drink in everything from my experiences.
Herein are my musings and thoughts regarding the last year.
Leaving AWS
I still think about my time at AWS:
it was a short, but very sweet and formative period for me.
Out of the ashes of the Broadcom / VMware acquisition news,
an announcement that many felt was deeply misaligned with VMware&rsquo;s Kubernetes vision,
I went searching for something else in mid 2022.
When I eventually joined the Amazon Linux and Bottlerocket team, I felt I had found a new home among people I related to:
peers who were passionate and deeply curious about programming, the art of computer science, and Linux."><meta name=author content><link rel=canonical href=https://johncodes.com/posts/2024/01-01-in-review/><link crossorigin=anonymous href=/assets/css/stylesheet.9329d037bc79464b26647fb72e079cd738f5d2418b1df4da3b515db9e22cb4d9.css integrity="sha256-kynQN7x5RksmZH+3Lgec1zj10kGLHfTaO1FdueIstNk=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://johncodes.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://johncodes.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://johncodes.com/favicon-32x32.png><link rel=apple-touch-icon href=https://johncodes.com/apple-touch-icon.png><link rel=mask-icon href=https://johncodes.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://johncodes.com/posts/2024/01-01-in-review/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta property="og:title" content="2023 in review"><meta property="og:description" content="I had a huge year.
And every year, around this time, when I have a well deserved opportunity to
take a break and prepare for the next year, I like to reflect:
think on the year&rsquo;s accomplishments, derive some lessons learned, and drink in everything from my experiences.
Herein are my musings and thoughts regarding the last year.
Leaving AWS
I still think about my time at AWS:
it was a short, but very sweet and formative period for me.
Out of the ashes of the Broadcom / VMware acquisition news,
an announcement that many felt was deeply misaligned with VMware&rsquo;s Kubernetes vision,
I went searching for something else in mid 2022.
When I eventually joined the Amazon Linux and Bottlerocket team, I felt I had found a new home among people I related to:
peers who were passionate and deeply curious about programming, the art of computer science, and Linux."><meta property="og:type" content="article"><meta property="og:url" content="https://johncodes.com/posts/2024/01-01-in-review/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-01-01T09:00:00+00:00"><meta property="article:modified_time" content="2024-01-01T09:00:00+00:00"><meta property="og:site_name" content="John-McBride"><meta name=twitter:card content="summary"><meta name=twitter:title content="2023 in review"><meta name=twitter:description content="I had a huge year.
And every year, around this time, when I have a well deserved opportunity to
take a break and prepare for the next year, I like to reflect:
think on the year&rsquo;s accomplishments, derive some lessons learned, and drink in everything from my experiences.
Herein are my musings and thoughts regarding the last year.
Leaving AWS
I still think about my time at AWS:
it was a short, but very sweet and formative period for me.
Out of the ashes of the Broadcom / VMware acquisition news,
an announcement that many felt was deeply misaligned with VMware&rsquo;s Kubernetes vision,
I went searching for something else in mid 2022.
When I eventually joined the Amazon Linux and Bottlerocket team, I felt I had found a new home among people I related to:
peers who were passionate and deeply curious about programming, the art of computer science, and Linux."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://johncodes.com/posts/"},{"@type":"ListItem","position":2,"name":"2023 in review","item":"https://johncodes.com/posts/2024/01-01-in-review/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"2023 in review","name":"2023 in review","description":"I had a huge year.\nAnd every year, around this time, when I have a well deserved opportunity to take a break and prepare for the next year, I like to reflect: think on the year\u0026rsquo;s accomplishments, derive some lessons learned, and drink in everything from my experiences.\nHerein are my musings and thoughts regarding the last year.\nLeaving AWS I still think about my time at AWS: it was a short, but very sweet and formative period for me. Out of the ashes of the Broadcom / VMware acquisition news, an announcement that many felt was deeply misaligned with VMware\u0026rsquo;s Kubernetes vision, I went searching for something else in mid 2022. When I eventually joined the Amazon Linux and Bottlerocket team, I felt I had found a new home among people I related to: peers who were passionate and deeply curious about programming, the art of computer science, and Linux.\n","keywords":[],"articleBody":"I had a huge year.\nAnd every year, around this time, when I have a well deserved opportunity to take a break and prepare for the next year, I like to reflect: think on the year’s accomplishments, derive some lessons learned, and drink in everything from my experiences.\nHerein are my musings and thoughts regarding the last year.\nLeaving AWS I still think about my time at AWS: it was a short, but very sweet and formative period for me. Out of the ashes of the Broadcom / VMware acquisition news, an announcement that many felt was deeply misaligned with VMware’s Kubernetes vision, I went searching for something else in mid 2022. When I eventually joined the Amazon Linux and Bottlerocket team, I felt I had found a new home among people I related to: peers who were passionate and deeply curious about programming, the art of computer science, and Linux.\nBut something I’ve come to grips with, and continue to digest since leaving, is just how burned out I actually was at AWS. The team was amazing, I got to work in Rust every single day, I was surrounded by individuals I looked up to and respected, and I was living my dream of building a Linux distribution in the open source. And yet, expectations were lofty. There was little room for error. Constant shifting organizational priorities. Leadership re-orgs. And a new, ambiguous return to office policy with the looming potential of having to eventually move to Seattle. It was a very befuddling decision to me: the entire Bottlerocket team was distributed all around the world. Why “return to team” when the team was fully remote and async to begin with?\nAll of that and I was coming off a relatively high pressure team at VMware shipping (and eventually deprecating) TCE.\n“Customer obsession” is probably Amazon’s deepest principle. And it’s embodied well throughout AWS: people legitimately care about shipping the best stuff for customers and delighting them with their work. But for the individual contributor, like me, leadership can wield it as justification to push beyond the bounds of what good work life balance is.\nBut, in the end, my burnout was no one’s fault exactly: sometimes these things just happen from a stint of bad luck. I joined AWS just before a tumultuous time in the market where the software engineer career path would drastically contract, layoffs would abound, and the pressure would be on for teams to ship real value that made their engineering headcount make sense. I was thankful to still have a job but I also could have done a much better job of setting clear work / life boundaries and finding balance: one of the tricky things I’m learning as I grow deeper into my tech career is that, while I deeply love and enjoy what I do, “variety is the spice of life” and finding a balance outside of tech is key to having a fruitful and enjoyable long term tech career.\nI’m very proud of alot of the work I did at AWS: there were some really tricky problems to solve. Here is some of the work I’m most proud of at AWS over the last year:\nv1.0.0 GA release of the Bottlerocket update-operator: this was a pretty huge undertaking. When I first joined the Bottlerocket team, there was a big backlog of things that needed to be fixed in the kubernetes update operator before we could consider it GA. For those curious, the Bottlerocket update-operator, or more affectionately called “brupop”, is a kubernetes operator system for automatic and continuous upgrade of Bottlerocket host nodes in a kubernetes cluster: this is great because someone operating a k8s cluster with Bottlerocket nodes will almost always want to consume the latest changes from our distro stream. These upgrades often included security patches and performance improvements. In order to cut this as GA, there were a number of huge refactors that needed to go in (including a deep dive on enabling mTLS between our API and operator pods, removing a long standing transient dependency on openssl, and refactoring massive amounts of code to enable the use of helm (which customers really wanted). Huge shoutout to my counterpart, Tianhao, for partnering on this massive achievement with me and the team! I learned alot from working with you!! Vending go modules using the custom Bottlerocket buildsys: the Bottlerocket buildsys is a mechanism to build the Bottlerocket operating system artifacts. Much easier said then done: because of Bottlerocket’s unique security constraints, use of selinux, and containerization paradigm, we had to find ways to consume upstream files (often in RPMs) in a reproducible manner where we could be assured source files had not been tampered with. Several Go modules were used throughout the OS which presented unique contraints when consuming and building those targets. This PR enabled Go modules to be vendored, checked, consumed, and built, all from within our internal build system: while this was early work, it set the stage for my presence on the team. After this, I felt I became the sort of “Go guy” and I often fielded bumping the version of Go we built with when new security releases were dropped, owning a few of our bespoke first party Go modules, working with internal Go teams to get new features and fixes into Bottlerocket when necessary, and much more. Amazon has a very healthy Go ecosystem and I’m excited to see what the teams do with it in the future! Lesson: Recognize the cinders of burnout before it becomes an all consuming flame. And do what you need to do in your life to find balance. Sometimes things happen. And you can’t always control them: what you can control is how you react.\nJoining OpenSauced Serendipitously, early in 2023, I had connected with bdougie, CEO of OpenSauced, the self proclaimed “Beyonce of open source”. We chatted a few times and I realized his vision for building tooling and platforms for open source maintainers and enablers was exactly what I’d been missing in my own personal open source contributions and work in AWS open source.\nSo many times I found myself asking “who exactly is this?” or “will this project accept contributions ..?” or “is this project’s community a welcoming one?” when working in open source.\nJoining a very early stage startup is something I’ve always wanted to try: you hear these legendary stories of people in the early 90s and 2000s solving huge problems with technology out of their garages (thankfully, we’re not running OpenSauced out of bdougie’s garage, we’re fully remote!)\nI followed my gut, trusted my instinct, and joined OpenSauced in mid 2023, leaving behind a very good and comfortable job at AWS: what an incredible decision! Since then, I’ve learned alot, been building alot of things, and have shipped a number of big enhancements to our data pipelines, backend infrastructure, frontend, how we approach building metrics and insights around open source contributions, and much more. I deeply believe that in 2024, we will have some incredible things to show off.\nSome public OpenSauced work I’m most proud of:\nEfficiently caching and ingesting git repos: I’ve written about this before, but one of the many challenges in building ontop of Git and Git based platforms is how you efficiently pull down new changes from repos (without having to clone the whole thing over and over again. Such a waste!) We needed a mechanism that could introspect individual commits in git repos to then derive insights from: enter the pizza oven, a Go based web server for cloning repos to disc, introspecting commits, and upserting new commits it sees to a database. one of the major efficiency bumps it gets is my implementation of an LRU cache: a caching mechanisms that drops the “least used” member when the cache is full. I could go very deep into this project, but i encourage you to read more about it here: https://dev.to/opensauced/caching-git-repos-a-deep-dive-into-opensauceds-pizza-oven-service-49nf https://dev.to/opensauced/how-we-made-our-go-microservice-24x-faster-5h3l The OpenSauced pizza CLI: OpenSauced isn’t just a web app for metrics and insights. It’s a software platform that is made to enable people building and consuming in the open. One thing we recognized was missing from our suite of tools is a CLI: the pizza CLI is a Go, Cobra based CLI that integrates with the OpenSauced API, bringing deeper capabilities to people who want to integrate OpenSauced into their CI/CD pipelines, scripts, or internal reporting tools. Shipping an OpenSauced Go client: alongside the OpenSauced CLI is a Go based client for the OpenSauced API. This enables anyone using Go to build ontop of our API and integrate deeply with our platform. Integrating realtime, events driven data into OpenSauced: the cat’s abit out of the bag on this one, and there is so much more to come, but I’ve been heads down over the last month or so shipping new infrastructure and data pipelines to integrate GitHub’s realtime events data into OpenSauced. Much of this is possible through the magic of the Timescale time series database: this gives us the power of leveraging Postgres alongside time series events data from GitHub. Check out the initial integration and be on the lookout for some really incredible improvements to the platform through these new mechanisms. Lesson: In 1994, Jeff Bezos took a huge leap of faith, quit his well paying, comfortable job in New York City to start Amazon: \"… I decided that if I didn’t at least give it my best shot, I was going to regret not trying to participate in this thing called the internet that I thought was going to be a big deal\".\nTake a leap of faith once in awhile. Trust your gut, take that opportunity, especially if you’ve always wanted to and it makes sense.\nCobra In 2023, along with the help of the amazing Go and Cobra community, we shipped 2 massive cobra releases: even while taking a break from maintaining Cobra, I found it deeply rewarding to give back to the community and continue maintenance of this incredibly important project.\nHere are some of my favorite things we shipped in Cobra this last year:\nSupport for usage of Cobra as a meta “plugin” framework: many tools, like kubectl can have “plugins” that you add to the top level CLI. These then get consumed through that top level CLI as a nice and comprehensive silo for your kubectl needs. We did something very similar with the tanzu CLI (although we built alot of custom software to make it work), this now has much better support directly in Cobra for plugin completions, command paths, etc. Completions support keeps getting better: powershell 7.2+ is now supported, there’s better support for bash, zsh, and fish, and we shipped many fixes to improve the overall quality of life when using completions and writing CLIs for completions. Here’s to much more cobra joy in 2024!!\nLesson: Taking breaks is a good thing. Come back to what brings you joy.\nDeeper into Neovim Part of me wondered when I joined AWS if my workflows in Neovim would be able to scale and keep up: TLDR, they did and they still do. Although, it required some continous tweaking.\nHere are a few of my favorite little tidbits of neovim goodness from 2023:\nmason.nvim: Mason is what I personally would consider one of Neovim’s most important 3rd party projects. It would not surprise me if it eventually was integrated directly into Neovim itself. Mason is a sort of manager of editor tooling, primarily LSP servers, linters, formaters, and the like. It provides a thin, simple interface for installing, managing, upgrading, and integrating with those tools. You might not think this is a big deal (\"another package manager??\"), but when you think about the effort and pain of setting up a new neovim environment (having to manually install and integrate gopls for Go development, having to manually install and integrate cargo for rust development, having to manually install and integrate eslint for Typescript development, etc. etc.), you realize that there is alot of 3rd party tooling you rely on. Using mason.nvim makes it so simple and easy. oil.nvim: Many people are familiar with vim-vinegar, a netrw enhancement for file explorering in vim. oil.nvim takes that concept and expands on it providing the ability to edit your filesystem in a normal nvim buffer. For a long time, I had been using a seperate tmux pane to do file system edits with mv, cp, and all the other traditional linux utilities. It was fine, but I really was missing the speed and power that oil.nvim gives you. This was sort of one of those things I didn’t know I was missing until I started using it but wow has it enhanced my workflow greatly. Highly, highly recommended! nvim-llama: I built a small, basic plugin that integrates Ollama docker containers (see the LLM section below) into neovim. I really love the idea of using local large language models and not ones as part of services: maybe it’s my dogmatic, Stallman view of open source software and services out in the wild, gut this was a great exercise in building a neovim plugin, letting the world know about it, and getting some really good feedback to improve its usage. Lesson Building good habits around things that improve your workflow is an investment I’m still greatly benefiting from. Take the time to know your tooling very well: these are compounding skills that can be applied to a wide range of disciplines.\nUsing LLMs I was pretty skeptical of AI technology towards the end of 2022: could Large Language Models and their interfaces, like ChatGPT, really become apart of my workflows?\nI think I’ve surprised myself: in some ways, using LLMs has indeed become a huge part of my workflows. My original, fear based assumption that this meant I’d no longer be able to write as much code as before was baseless: it’s a tool, just like anything else. And if anything, it’s allowed me to write more code. But I’ve hit many of the snags with using LLMs: I’ve gotten some nasty hallucinations and I’ve found areas that LLMs just don’t know about (for example, in early 2023, LLM’s rust knowledge was pretty poor). Still, I’ve found it to be a really useful tool and almost essential to quickly discovering new knowledge.\nHere’s how I used LLMs in 2023:\nSubscribed to ChatGPT plus. A month or so latter, canceled. Used Google’s Bard on occasion: Google definitely seems to have some of the best training data (this shouldn’t be a surprise to anyone). Started using local LLMs with llama.cpp and Meta’s Llama 2 and Code Llama models. Started using Ollama in Docker for a seamless DX and user experience. Much easier to integrate a docker container. Use https://huggingface.co/chat/ to experiment with open source, unfiltered, cutting edge models. Lesson The biggest shift in my mental paradigm around LLMs is that running them locally is actually not as bad as you’d think: Apple’s newest M chipsets are honestly powerhouses and I’ve had amazing results with some of the 7B and 13B parameter models: I believe the future of open source AI technology is very bright and I hope it grows to rival that of major tech companies building this technology on proprietary software. Long live the open source movement!! And long live open source LLMs!\nSocial media I still don’t know what the hell I’m doing with social media: some days it feels like a huge burden, something I have to do in order to stay engaged with people in the tech communities I’m apart of.\nOther days, I feel so thankful to live at a time in history when I can connect with other technologists, scientist, and engineers around the world seamlessly.\nI’m not sure if it’s a curse upon society or a blessing: but one thing I’ve realized, somewhere through the torrent of tiktok videos I’ve consumed, at least for me, anything more than very mild social media consumption is a detriment to my well-being.\nI’m certain that being burned out at AWS was in some ways due to my social media use: it was hard to not doom scroll news about layoffs, the stock market, or the waning tech job field. It was hard to not see viral posts like “how I became a 10x engineer” or “how I made 1 million dollars as a software engineer”. Eventually, unconsciously, those words start to change your mindset. And overall, it just made me discontent: this all reminds me of the famous Theodore Roosevelt quote:\nComparison is the thief of joy.\nLesson Mass social media consumption isn’t good for me. I’m still figuring a balance out, but for now, to start, I’m limiting social media access on my phone.\nHere’s to many more years! Good luck in the new year!!\n","wordCount":"2810","inLanguage":"en","datePublished":"2024-01-01T09:00:00Z","dateModified":"2024-01-01T09:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://johncodes.com/posts/2024/01-01-in-review/"},"publisher":{"@type":"Organization","name":"John McBride","logo":{"@type":"ImageObject","url":"https://johncodes.com/favicon.ico"}}}</script></head><body class=dark id=top><script>localStorage.getItem("pref-theme")==="light"&&document.body.classList.remove("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://johncodes.com/ accesskey=h title="John McBride (Alt + H)">John McBride</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://johncodes.com/archives title=Writing><span>Writing</span></a></li><li><a href=https://johncodes.com/index.xml title=RSS><span>RSS</span></a></li><li><a href=https://johncodes.com/talks/ title=Talks><span>Talks</span></a></li><li><a href=https://johncodes.com/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://johncodes.com/about title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>2023 in review</h1><div class=post-meta><span title='2024-01-01 09:00:00 +0000 UTC'>January 1, 2024</span></div></header><div class=post-content><p>I had a huge year.</p><p>And every year, around this time, when I have a well deserved opportunity to
take a break and prepare for the next year, I like to reflect:
think on the year&rsquo;s accomplishments, derive some lessons learned, and drink in everything from my experiences.</p><p>Herein are my musings and thoughts regarding the last year.</p><h2 id=leaving-aws>Leaving AWS<a hidden class=anchor aria-hidden=true href=#leaving-aws>#</a></h2><p>I still think about my time at AWS:
it was a short, but very sweet and formative period for me.
Out of the ashes of the Broadcom / VMware acquisition news,
an announcement that many felt was deeply misaligned with VMware&rsquo;s Kubernetes vision,
I went searching for something else in mid 2022.
When I eventually joined the Amazon Linux and Bottlerocket team, I felt I had found a new home among people I related to:
peers who were passionate and deeply curious about programming, the art of computer science, and Linux.</p><p>But something I&rsquo;ve come to grips with, and continue to digest since leaving,
is just how burned out I actually was at AWS.
The team was amazing, I got to work in Rust every single day, I was surrounded by individuals I looked up to and respected,
and I was living my dream of building a Linux distribution in the open source.
And yet, expectations were lofty. There was little room for error.
Constant shifting organizational priorities. Leadership re-orgs.
And a new, ambiguous return to office policy with the looming potential of having to eventually move to Seattle.
It was a very befuddling decision to me: the entire Bottlerocket team was distributed all around the world.
Why &ldquo;return to team&rdquo; when the team was fully remote and async to begin with?</p><p>All of that <em>and</em> I was coming off a relatively high pressure team at VMware shipping
(<a href=https://github.com/vmware-tanzu/community-edition>and eventually deprecating</a>) TCE.</p><p><em>&ldquo;Customer obsession&rdquo;</em> is probably Amazon&rsquo;s deepest principle.
And it&rsquo;s embodied well throughout AWS:
people legitimately care about shipping the best stuff for customers
and delighting them with their work.
But for the individual contributor, like me, leadership can wield it
as justification to push beyond the bounds of what good work life balance is.</p><p>But, in the end, my burnout was no one&rsquo;s fault exactly: sometimes these things just happen from a stint of bad luck.
I joined AWS just before a tumultuous time in the market
where the software engineer career path would drastically contract,
layoffs would abound,
and the pressure would be on for teams to ship real value that made their engineering headcount make sense.
I was thankful to still have a job but
I also could have done a much better job of setting clear work / life boundaries
and finding balance: one of the tricky things I&rsquo;m learning as I grow deeper into my tech career
is that, while I <em>deeply</em> love and enjoy what I do,
<em>&ldquo;variety is the spice of life&rdquo;</em> and finding a balance <em>outside</em> of tech is key to having a fruitful
and enjoyable long term tech career.</p><p>I&rsquo;m very proud of alot of the work I did at AWS: there were some <em>really</em> tricky problems to solve. Here is some of the work I&rsquo;m most proud of at AWS over the last year:</p><ul><li><a href=https://github.com/bottlerocket-os/bottlerocket-update-operator/pull/325>v1.0.0 GA release of the Bottlerocket update-operator</a>: this was a pretty huge undertaking. When I first joined the Bottlerocket team, there was a big backlog of things that needed to be fixed in the kubernetes update operator before we could consider it GA. For those curious, the Bottlerocket update-operator, or more affectionately called &ldquo;brupop&rdquo;, is a kubernetes operator system for automatic and continuous upgrade of Bottlerocket host nodes in a kubernetes cluster: this is great because someone operating a k8s cluster with Bottlerocket nodes will almost always want to consume the latest changes from our distro stream. These upgrades often included security patches and performance improvements. In order to cut this as GA, there were a number of huge refactors that needed to go in (including a deep dive on <a href=https://github.com/bottlerocket-os/bottlerocket-update-operator/pull/340>enabling mTLS between our API and operator pods</a>, <a href=https://github.com/bottlerocket-os/bottlerocket-update-operator/pull/401>removing a long standing transient dependency on <code>openssl</code></a>, and <a href=https://github.com/bottlerocket-os/bottlerocket-update-operator/pull/350>refactoring massive amounts of code to enable the use of <code>helm</code></a> (which customers really wanted). <em>Huge</em> shoutout to my counterpart, <a href=https://github.com/gthao313>Tianhao</a>, for partnering on this massive achievement with me and the team! I learned alot from working with you!!</li><li><a href=https://github.com/bottlerocket-os/bottlerocket/pull/2378>Vending go modules using the custom Bottlerocket <code>buildsys</code></a>: the Bottlerocket <code>buildsys</code> is a mechanism to build the Bottlerocket operating system artifacts. Much easier said then done: because of Bottlerocket&rsquo;s unique security constraints, use of <code>selinux</code>, and containerization paradigm, we had to find ways to consume upstream files (often in RPMs) in a reproducible manner where we could be assured source files had not been tampered with. Several Go modules were used throughout the OS which presented unique contraints when consuming and building those targets. This PR enabled Go modules to be vendored, checked, consumed, and built, all from within our internal build system: while this was early work, it set the stage for my presence on the team. After this, I felt I became the sort of &ldquo;Go guy&rdquo; and I often fielded bumping the version of Go we built with when new security releases were dropped, owning a few of our bespoke first party Go modules, working with internal Go teams to get new features and fixes into Bottlerocket when necessary, and much more. Amazon has a very healthy Go ecosystem and I&rsquo;m excited to see what the teams do with it in the future!</li></ul><h4 id=lesson>Lesson:<a hidden class=anchor aria-hidden=true href=#lesson>#</a></h4><p>Recognize the cinders of burnout before it becomes an all consuming flame. And do what you need to do in your life to find balance.
Sometimes things happen. And you can&rsquo;t always control them: what you can control is how you react.</p><h2 id=joining-opensauced>Joining OpenSauced<a hidden class=anchor aria-hidden=true href=#joining-opensauced>#</a></h2><p>Serendipitously, early in 2023, I had connected with <a href=https://twitter.com/bdougieYO>bdougie</a>,
CEO of OpenSauced, the self proclaimed <a href=https://thenewstack.io/after-github-brian-douglas-builds-an-open-source-startup/><em>&ldquo;Beyonce of open source&rdquo;</em></a>. We chatted a few times and I realized his vision for building tooling and platforms <em>for</em> open source maintainers and enablers was exactly what I&rsquo;d been missing <em>in my own</em> personal open source contributions and work in AWS open source.</p><p>So many times I found myself asking <em>&ldquo;who exactly is this?&rdquo;</em> or <em>&ldquo;will this project accept contributions ..?&rdquo;</em> or <em>&ldquo;is this project&rsquo;s community a welcoming one?&rdquo;</em> when working in open source.</p><p>Joining a very early stage startup is something I&rsquo;ve always wanted to try: you hear these legendary stories of people in the early 90s and 2000s solving huge problems with technology out of their garages (thankfully, we&rsquo;re not running OpenSauced out of bdougie&rsquo;s garage, we&rsquo;re fully remote!)</p><p>I followed my gut, trusted my instinct, and joined OpenSauced in mid 2023, leaving behind a very good and comfortable job at AWS: what an incredible decision! Since then, I&rsquo;ve learned <em>alot</em>, been building <em>alot</em> of things, and have shipped a number of big enhancements to our data pipelines, backend infrastructure, frontend, how we approach building metrics and insights around open source contributions, and much more. I deeply believe that in 2024, we will have some incredible things to show off.</p><p>Some public OpenSauced work I&rsquo;m most proud of:</p><ul><li><a href=https://github.com/open-sauced/go-api>Efficiently caching and ingesting git repos</a>: I&rsquo;ve written about this before, but one of the many challenges in building ontop of Git and Git based platforms is how you efficiently pull down new changes from repos (without having to clone the whole thing over and over again. Such a waste!) We needed a mechanism that could introspect individual commits in git repos to then derive insights from: enter the pizza oven, a Go based web server for cloning repos to disc, introspecting commits, and upserting new commits it sees to a database. one of the major efficiency bumps it gets is my implementation of an LRU cache: a caching mechanisms that drops the &ldquo;least used&rdquo; member when the cache is full. I could go <em>very</em> deep into this project, but i encourage you to read more about it here:<ul><li><a href=https://dev.to/opensauced/caching-git-repos-a-deep-dive-into-opensauceds-pizza-oven-service-49nf>https://dev.to/opensauced/caching-git-repos-a-deep-dive-into-opensauceds-pizza-oven-service-49nf</a></li><li><a href=https://dev.to/opensauced/how-we-made-our-go-microservice-24x-faster-5h3l>https://dev.to/opensauced/how-we-made-our-go-microservice-24x-faster-5h3l</a></li></ul></li><li><a href=https://github.com/open-sauced/pizza-cli>The OpenSauced <code>pizza</code> CLI</a>: OpenSauced isn&rsquo;t just a web app for metrics and insights. It&rsquo;s a software platform that is made to enable people building and consuming in the open. One thing we recognized was missing from our suite of tools is a CLI: the <code>pizza</code> CLI is a Go, Cobra based CLI that integrates with the OpenSauced API, bringing deeper capabilities to people who want to integrate OpenSauced into their CI/CD pipelines, scripts, or internal reporting tools.<ul><li>Shipping an OpenSauced Go client: alongside the OpenSauced CLI is <a href=https://github.com/open-sauced/go-api>a Go based client for the OpenSauced API</a>. This enables <em>anyone</em> using Go to build ontop of our API and integrate deeply with our platform.</li></ul></li><li>Integrating realtime, events driven data into OpenSauced: the cat&rsquo;s <em>abit</em> out of the bag on this one, and there is <em>so</em> much more to come, but I&rsquo;ve been heads down over the last month or so shipping new infrastructure and data pipelines to integrate GitHub&rsquo;s realtime events data into OpenSauced. Much of this is possible through the magic of the Timescale time series database: this gives us the power of leveraging Postgres <em>alongside</em> time series events data from GitHub. <a href=https://github.com/open-sauced/app/pull/2293>Check out the initial integration</a> and be on the lookout for some <em>really</em> incredible improvements to the platform through these new mechanisms.</li></ul><h4 id=lesson-1>Lesson:<a hidden class=anchor aria-hidden=true href=#lesson-1>#</a></h4><p>In 1994, Jeff Bezos took a huge leap of faith, quit his well paying, comfortable job in New York City <a href=https://www.aboutamazon.com/news/policy-news-views/statement-by-jeff-bezos-to-the-u-s-house-committee-on-the-judiciary>to start Amazon</a>: <em>"&mldr; I decided that if I didn’t at least give it my best shot, I was going to regret not trying to participate in this thing called the internet that I thought was going to be a big deal"</em>.</p><p>Take a leap of faith once in awhile. Trust your gut, take that opportunity, especially if you&rsquo;ve always wanted to and it makes sense.</p><h2 id=cobra>Cobra<a hidden class=anchor aria-hidden=true href=#cobra>#</a></h2><p>In 2023, along with the help of the amazing Go and Cobra community, <a href=https://github.com/spf13/cobra/releases>we shipped 2 massive cobra releases</a>:
even while taking a break from maintaining Cobra,
I found it deeply rewarding to give back to the community
and continue maintenance of this incredibly important project.</p><p>Here are some of my favorite things we shipped in Cobra this last year:</p><ul><li>Support for usage of Cobra as a meta &ldquo;plugin&rdquo; framework: many tools, like <code>kubectl</code>
can have &ldquo;plugins&rdquo; that you add to the top level CLI. These then get consumed through that top level CLI
as a nice and comprehensive silo for your <code>kubectl</code> needs.
We did something <em>very</em> similar with the <code>tanzu</code> CLI (although we built alot of custom software to make it work),
this now has much better support directly in Cobra for plugin completions, command paths, etc.</li><li>Completions support keeps getting better: <code>powershell</code> 7.2+ is now supported, there&rsquo;s better
support for <code>bash</code>, <code>zsh</code>, and <code>fish</code>, and we shipped <em>many</em> fixes to improve the overall
quality of life when using completions and writing CLIs for completions.</li></ul><p>Here&rsquo;s to much more cobra joy in 2024!!</p><h4 id=lesson-2>Lesson:<a hidden class=anchor aria-hidden=true href=#lesson-2>#</a></h4><p>Taking breaks is a good thing. Come back to what brings you joy.</p><h2 id=deeper-into-neovim>Deeper into Neovim<a hidden class=anchor aria-hidden=true href=#deeper-into-neovim>#</a></h2><p>Part of me wondered when I joined AWS if my workflows in Neovim would be able to scale and keep up: TLDR, they did and they still do. Although, it required some continous tweaking.</p><p>Here are a few of my favorite little tidbits of neovim goodness from 2023:</p><ul><li><a href=https://github.com/williamboman/mason.nvim><code>mason.nvim</code></a>: Mason is what I personally would consider
one of Neovim&rsquo;s most important 3rd party projects. It would not surprise me if it eventually was
integrated directly into Neovim itself. Mason is a sort of manager of editor tooling, primarily
LSP servers, linters, formaters, and the like. It provides a thin, simple interface for
installing, managing, upgrading, and integrating with those tools.
You might not think this is a big deal ("<em>another</em> package manager??"),
but when you think about the effort and pain of setting up a new neovim environment
(having to manually install and integrate <code>gopls</code> for Go development,
having to manually install and integrate <code>cargo</code> for rust development,
having to manually install and integrate <code>eslint</code> for Typescript development, etc. etc.),
you realize that there is <em>alot</em> of 3rd party tooling you rely on. Using <code>mason.nvim</code> makes it so simple and easy.</li><li><a href=https://github.com/stevearc/oil.nvim><code>oil.nvim</code></a>: Many people are familiar with <code>vim-vinegar</code>, a <code>netrw</code> enhancement for file explorering in vim.
<code>oil.nvim</code> takes that concept and expands on it providing the ability to edit your filesystem
<em>in a normal nvim buffer</em>. For a long time, I had been using a seperate tmux pane to do file system edits
with <code>mv</code>, <code>cp</code>, and all the other traditional linux utilities. It was fine, but I really was missing
the speed and power that <code>oil.nvim</code> gives you. This was sort of one of those things I didn&rsquo;t know
I was missing until I started using it but wow has it enhanced my workflow greatly. Highly, highly recommended!</li><li><a href=https://github.com/jpmcb/nvim-llama><code>nvim-llama</code></a>: I built a small, basic plugin that integrates Ollama docker containers (see the LLM section below) into neovim.
I really love the idea of using <em>local</em> large language models and not ones as part of services:
maybe it&rsquo;s my dogmatic, Stallman view of open source software and services out in the wild,
gut this was a great exercise in building a neovim plugin, letting the world know about it,
and getting some really good feedback to improve its usage.</li></ul><h4 id=lesson-3>Lesson<a hidden class=anchor aria-hidden=true href=#lesson-3>#</a></h4><p>Building good habits around things that improve your workflow is an investment I&rsquo;m still greatly benefiting from.
Take the time to know your tooling very well: these are compounding skills that can be applied to a wide range of disciplines.</p><h2 id=using-llms>Using LLMs<a hidden class=anchor aria-hidden=true href=#using-llms>#</a></h2><p>I was pretty skeptical of AI technology towards the end of 2022:
could Large Language Models and their interfaces, like ChatGPT, really become apart of my workflows?</p><p>I think I&rsquo;ve surprised myself: in some ways, using LLMs has indeed become a huge part of my workflows.
My original, fear based assumption that this meant I&rsquo;d no longer be able to write as much code as before was baseless:
it&rsquo;s a tool, just like anything else. And if anything, it&rsquo;s allowed me to write <em>more</em> code.
But I&rsquo;ve hit many of the snags with using LLMs: I&rsquo;ve gotten some nasty hallucinations and
I&rsquo;ve found areas that LLMs just don&rsquo;t know about (for example, in early 2023, LLM&rsquo;s rust knowledge was pretty poor).
Still, I&rsquo;ve found it to be a really useful tool and almost essential to quickly discovering new knowledge.</p><p>Here&rsquo;s how I used LLMs in 2023:</p><ul><li>Subscribed to ChatGPT plus. A month or so latter, canceled.</li><li>Used Google&rsquo;s Bard on occasion: Google definitely seems to have some of the best training data (this shouldn&rsquo;t be a surprise to anyone).</li><li>Started using <a href=https://github.com/ggerganov/llama.cpp/>local LLMs with <code>llama.cpp</code> </a>and Meta&rsquo;s Llama 2 and Code Llama models.</li><li>Started using <a href=https://github.com/jmorganca/ollama>Ollama</a> in Docker for a seamless DX and user experience. Much easier to integrate a docker container.</li><li>Use <a href=https://huggingface.co/chat/>https://huggingface.co/chat/</a> to experiment with open source, unfiltered, cutting edge models.</li></ul><h4 id=lesson-4>Lesson<a hidden class=anchor aria-hidden=true href=#lesson-4>#</a></h4><p>The biggest shift in my mental paradigm around LLMs is that running them locally
is actually not as bad as you&rsquo;d think: Apple&rsquo;s newest M chipsets are honestly powerhouses
and I&rsquo;ve had amazing results with some of the 7B and 13B parameter models:
I believe the future of open source AI technology is very bright and I hope
it grows to rival that of major tech companies building this technology on proprietary software.
Long live the open source movement!! And long live open source LLMs!</p><h2 id=social-media>Social media<a hidden class=anchor aria-hidden=true href=#social-media>#</a></h2><p>I still don&rsquo;t know what the hell I&rsquo;m doing with social media: some days it feels like a huge burden,
something I <em>have</em> to do in order to stay engaged with people in the tech communities I&rsquo;m apart of.</p><p>Other days, I feel so thankful to live at a time in history when I can connect with other technologists,
scientist, and engineers around the world seamlessly.</p><p>I&rsquo;m not sure if it&rsquo;s a curse upon society or a blessing: but one thing I&rsquo;ve realized,
somewhere through the torrent of tiktok videos I&rsquo;ve consumed, at least for me, anything
more than very mild social media consumption is a detriment to my well-being.</p><p>I&rsquo;m certain that being burned out at AWS was in some ways due to my social media use:
it was hard to not doom scroll news about layoffs, the stock market, or the waning tech job field.
It was hard to not see viral posts like <em>&ldquo;how I became a 10x engineer&rdquo;</em> or <em>&ldquo;how I made 1 million dollars as a software engineer&rdquo;</em>.
Eventually, unconsciously, those words start to change your mindset.
And overall, it just made me discontent: this all reminds me of the famous Theodore Roosevelt quote:</p><blockquote><p>Comparison is the thief of joy.</p></blockquote><h4 id=lesson-5>Lesson<a hidden class=anchor aria-hidden=true href=#lesson-5>#</a></h4><p>Mass social media consumption isn&rsquo;t good for me. I&rsquo;m still figuring a balance out, but for now, to start,
I&rsquo;m limiting social media access on my phone.</p><hr><p>Here&rsquo;s to many more years!
Good luck in the new year!!</p><hr><script src=https://giscus.app/client.js data-repo=jpmcb/blog data-repo-id="MDEwOlJlcG9zaXRvcnkxMTYxODMyNjg=" data-category="Blog comments" data-category-id=DIC_kwDOBuzQ5M4CTbHW data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=dark_dimmed data-lang=en data-loading=lazy crossorigin=anonymous async></script></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://johncodes.com/>John McBride</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>